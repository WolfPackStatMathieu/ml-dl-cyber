{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the JSON file\n",
    "file_path = '1716554847_127206(1).json'\n",
    "\n",
    "# Read the file line by line and parse each JSON object\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                _raw  \\\n",
      "0  May 24 14:33:29 172.22.7.248 May 24 14:33:29 P...   \n",
      "1  May 24 14:33:29 172.22.7.248 May 24 14:33:29 P...   \n",
      "\n",
      "                           _time action   app  bytes bytes_in bytes_out  \\\n",
      "0  2024-05-24T14:33:29.000+02:00     OK  HTTP  41591       68     41523   \n",
      "1  2024-05-24T14:33:29.000+02:00     OK  HTTP  26468       45     26423   \n",
      "\n",
      "                                           category charset  \\\n",
      "0  application/x-www-form-urlencoded; charset=UTF-8   UTF-8   \n",
      "1  application/x-www-form-urlencoded; charset=UTF-8   UTF-8   \n",
      "\n",
      "                                         client_type  ... timestartpos  \\\n",
      "0  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:1...  ...            0   \n",
      "1  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:1...  ...            0   \n",
      "\n",
      "                   uri_path uri_query  \\\n",
      "0    /fr/graphique/affaires             \n",
      "1  /fr/graphique/croissance             \n",
      "\n",
      "                                                 url  \\\n",
      "0  \"web4gfo.preprod.insee.fr:443/fr/graphique/aff...   \n",
      "1  \"web4gfo.preprod.insee.fr:443/fr/graphique/cro...   \n",
      "\n",
      "                  url_domain url_length user vendor_product              vip  \\\n",
      "0  \"web4gfo.preprod.insee.fr         52       F5 BIG-IP LTM  10.210.248.11%5   \n",
      "1  \"web4gfo.preprod.insee.fr         54       F5 BIG-IP LTM  10.210.248.11%5   \n",
      "\n",
      "                  virtual_server  \n",
      "0  /Common/pool_ppweb4gfoln071 0  \n",
      "1  /Common/pool_ppweb4gfoln071 0  \n",
      "\n",
      "[2 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'result' part of each JSON object and create a dataset\n",
    "results = [entry['result'] for entry in data]\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract variables from the _raw column\n",
    "def extract_variables(raw_string):\n",
    "    # Define the regular expression pattern with named groups\n",
    "    pattern = re.compile(\n",
    "        # Match timestamp (e.g., \"May 24 14:33:29\")\n",
    "        r'(?P<timestamp>[A-Za-z]+\\s+\\d+\\s+\\d+:\\d+:\\d+)\\s+'\n",
    "        # Match host IP (e.g., \"172.22.7.248\")\n",
    "        r'(?P<host_ip>\\d+\\.\\d+\\.\\d+\\.\\d+)\\s+'\n",
    "        # Match any alphanumeric characters, dashes, or dots (e.g., \"PD-HLB01-ID261.dc2.sia.priv\")\n",
    "        r'[A-Za-z0-9\\-\\.]+\\s+'\n",
    "        # Match the info level (e.g., \"info\")\n",
    "        r'(?P<info>[a-z]+)\\s+'\n",
    "        # Match tmm with digits in brackets (e.g., \"tmm[20235]\")\n",
    "        r'tmm\\[\\d+\\]:\\s+'\n",
    "        # Match the rule description\n",
    "        r'Rule\\s+/Common/Irule-Syslog-splunk_v2\\s+<HTTP_RESPONSE>:\\s+'\n",
    "        # Match src_ip (e.g., \"src_ip=\"10.92.115.117%5\"\")\n",
    "        r'src_ip=\"(?P<src_ip>[^\"]+)\",'\n",
    "        # Match vip (e.g., \"vip=\"10.210.248.11%5\"\")\n",
    "        r'vip=\"(?P<vip>[^\"]+)\",'\n",
    "        # Match http_method (e.g., \"http_method=\"POST\"\")\n",
    "        r'http_method=\"(?P<http_method>[^\"]+)\",'\n",
    "        # Match http_host (e.g., \"http_host=\"web4gfo.preprod.insee.fr:443\"\")\n",
    "        r'http_host=\"(?P<http_host>[^\"]+)\",'\n",
    "        # Match http_uri (e.g., \"http_uri=\"/fr/graphique/affaires\"\")\n",
    "        r'http_uri=\"(?P<http_uri>[^\"]+)\",'\n",
    "        # Match http_url (e.g., \"http_url=\"web4gfo.preprod.insee.fr:443/fr/graphique/affaires\"\")\n",
    "        r'http_url=\"(?P<http_url>[^\"]+)\",'\n",
    "        # Match http_version (e.g., \"http_version=\"1.1\"\")\n",
    "        r'http_version=\"(?P<http_version>[^\"]+)\",'\n",
    "        # Match http_user_agent (e.g., \"http_user_agent=\"Mozilla/5.0 ...\"\")\n",
    "        r'http_user_agent=\"(?P<http_user_agent>[^\"]+)\",'\n",
    "        # Match http_content_type (e.g., \"http_content_type=\"application/x-www-form-urlencoded; charset=UTF-8\"\")\n",
    "        r'http_content_type=\"(?P<http_content_type>[^\"]+)\",'\n",
    "        # Match http_referrer (e.g., \"http_referrer=\"https://web4gfo.preprod.insee.fr/fr/accueil\"\")\n",
    "        r'http_referrer=\"(?P<http_referrer>[^\"]+)\",'\n",
    "        # Match req_start_time (e.g., \"req_start_time=\"2024/05/24 14:33:29\"\")\n",
    "        r'req_start_time=\"(?P<req_start_time>[^\"]+)\",'\n",
    "        # Match cookie (e.g., \"cookie=\"JSESSIONID\"\")\n",
    "        r'cookie=\"(?P<cookie>[^\"]*)\",'\n",
    "        # Match user (e.g., \"user=\"\"\")\n",
    "        r'user=\"(?P<user>[^\"]*)\",'\n",
    "        # Match virtual_server (e.g., \"virtual_server=\"/Common/pool_ppweb4gfoln071 0\"\")\n",
    "        r'virtual_server=\"(?P<virtual_server>[^\"]+)\",'\n",
    "        # Match bytes_in (e.g., \"bytes_in=\"68\"\")\n",
    "        r'bytes_in=\"(?P<bytes_in>\\d+)\",'\n",
    "        # Match res_start_time (e.g., \"res_start_time=\"2024/05/24 14:33:29\"\")\n",
    "        r'res_start_time=\"(?P<res_start_time>[^\"]+)\",'\n",
    "        # Match node (e.g., \"node=\"10.210.56.47%5\"\")\n",
    "        r'node=\"(?P<node>[^\"]+)\",'\n",
    "        # Match node_port (e.g., \"node_port=\"80\"\")\n",
    "        r'node_port=\"(?P<node_port>\\d+)\",'\n",
    "        # Match http_status (e.g., \"http_status=\"200\"\")\n",
    "        r'http_status=\"(?P<http_status>\\d+)\",'\n",
    "        # Match req_elapsed_time (e.g., \"req_elapsed_time=\"193\"\")\n",
    "        r'req_elapsed_time=\"(?P<req_elapsed_time>\\d+)\",'\n",
    "        # Match bytes_out (e.g., \"bytes_out=\"41523\"\")\n",
    "        r'bytes_out=\"(?P<bytes_out>\\d+)\"'\n",
    "    )\n",
    "    match = pattern.match(raw_string)\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Columns:  []\n",
      "Original Columns:  ['_raw', '_time', 'action', 'app', 'bytes', 'bytes_in', 'bytes_out', 'category', 'charset', 'client_type', 'cookie', 'date_hour', 'date_mday', 'date_minute', 'date_month', 'date_second', 'date_wday', 'date_year', 'date_zone', 'dest', 'dest_addr', 'dest_ip', 'dest_port', 'dest_translated_ip', 'duration', 'eventtype', 'f5_bigip_server_host', 'host', 'http_content_type', 'http_host', 'http_method', 'http_referrer', 'http_referrer_domain', 'http_status', 'http_uri', 'http_url', 'http_user_agent', 'http_user_agent_length', 'http_version', 'index', 'is_f5_heartbeat', 'linecount', 'node', 'node_port', 'pool', 'protocol', 'punct', 'req_elapsed_time', 'req_start_time', 'res_start_time', 'response_code', 'rtt', 'site', 'source', 'sourcetype', 'splunk_server', 'src', 'src_addr', 'src_ip', 'status', 'tag', 'tag::eventtype', 'thruput', 'timeendpos', 'timestartpos', 'uri_path', 'uri_query', 'url', 'url_domain', 'url_length', 'user', 'vendor_product', 'vip', 'virtual_server']\n",
      "                           _time action   app  bytes bytes_in bytes_out  \\\n",
      "0  2024-05-24T14:33:29.000+02:00     OK  HTTP  41591       68     41523   \n",
      "1  2024-05-24T14:33:29.000+02:00     OK  HTTP  26468       45     26423   \n",
      "\n",
      "                                           category charset  \\\n",
      "0  application/x-www-form-urlencoded; charset=UTF-8   UTF-8   \n",
      "1  application/x-www-form-urlencoded; charset=UTF-8   UTF-8   \n",
      "\n",
      "                                         client_type      cookie  ...  \\\n",
      "0  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:1...  JSESSIONID  ...   \n",
      "1  Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:1...  JSESSIONID  ...   \n",
      "\n",
      "  timestartpos                  uri_path uri_query  \\\n",
      "0            0    /fr/graphique/affaires             \n",
      "1            0  /fr/graphique/croissance             \n",
      "\n",
      "                                                 url  \\\n",
      "0  \"web4gfo.preprod.insee.fr:443/fr/graphique/aff...   \n",
      "1  \"web4gfo.preprod.insee.fr:443/fr/graphique/cro...   \n",
      "\n",
      "                  url_domain url_length user vendor_product              vip  \\\n",
      "0  \"web4gfo.preprod.insee.fr         52       F5 BIG-IP LTM  10.210.248.11%5   \n",
      "1  \"web4gfo.preprod.insee.fr         54       F5 BIG-IP LTM  10.210.248.11%5   \n",
      "\n",
      "                  virtual_server  \n",
      "0  /Common/pool_ppweb4gfoln071 0  \n",
      "1  /Common/pool_ppweb4gfoln071 0  \n",
      "\n",
      "[2 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the _raw column and expand the dictionaries into columns\n",
    "extracted_df = results_df['_raw'].apply(lambda x: pd.Series(extract_variables(x)))\n",
    "\n",
    "# Concatenate the extracted columns with the original DataFrame\n",
    "final_df = pd.concat([results_df, extracted_df], axis=1)\n",
    "\n",
    "# Drop the original _raw column as it is no longer needed\n",
    "final_df = final_df.drop(columns=['_raw'])\n",
    "\n",
    "# Display the new columns\n",
    "new_columns = extracted_df.columns.tolist()\n",
    "print(\"New Columns: \", new_columns)\n",
    "\n",
    "# Display the original columns\n",
    "original_columns = results_df.columns.tolist()\n",
    "print(\"Original Columns: \", original_columns)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(final_df.head())\n",
    "\n",
    "# Optionally, save the final DataFrame to a CSV file\n",
    "final_df.to_csv('final_results_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
