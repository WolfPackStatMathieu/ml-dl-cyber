{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autre structure: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/mamba/lib/python3.12/site-packages (from -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2.16.1)\n",
      "Collecting pandas (from -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 2))\n",
      "  Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn (from -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 3))\n",
      "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting torch (from -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting seaborn (from -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 5))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting matplotlib (from -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading matplotlib-3.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/mamba/lib/python3.12/site-packages (from pandas->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 2)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/mamba/lib/python3.12/site-packages (from pandas->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 2)) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 2))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 3))\n",
      "  Downloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 3))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 3))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting filelock (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sympy (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/mamba/lib/python3.12/site-packages (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/mamba/lib/python3.12/site-packages (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4)) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading contourpy-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading fonttools-4.51.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting pillow>=8 (from matplotlib->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading pillow-10.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 6))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/mamba/lib/python3.12/site-packages (from jinja2->torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4)) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 4))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/mamba/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/mamba/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow->-r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt (line 1)) (0.1.2)\n",
      "Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m129.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m205.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.2/309.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m891.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, tzdata, threadpoolctl, sympy, scipy, pyparsing, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, kiwisolver, joblib, fonttools, filelock, cycler, contourpy, scikit-learn, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, matplotlib, seaborn, nvidia-cusolver-cu12, torch\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 filelock-3.14.0 fonttools-4.51.0 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.9.0 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pandas-2.2.2 pillow-10.3.0 pyparsing-3.1.2 scikit-learn-1.4.2 scipy-1.13.0 seaborn-0.13.2 sympy-1.12 threadpoolctl-3.5.0 torch-2.3.0 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/ml-dl-cyber/1-Quick-win/Good_Bad_queries\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Charger les données\n",
    "def load_data(filepath, label):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        data = [(line.strip(), label) for line in lines if line.strip()]\n",
    "    return data\n",
    "\n",
    "# Emplacements des fichiers\n",
    "bad_queries_path = 'badqueries.txt'\n",
    "good_queries_path = 'goodqueries.txt'\n",
    "\n",
    "# Charger et étiqueter les données\n",
    "bad_data = load_data(bad_queries_path, 1)  # Étiquette 1 pour les mauvaises requêtes\n",
    "good_data = load_data(good_queries_path, 0)  # Étiquette 0 pour les bonnes requêtes\n",
    "\n",
    "# Combinez les données dans un DataFrame\n",
    "all_data = pd.DataFrame(bad_data + good_data, columns=['query', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of balanced sampled data: (1342596, 2)\n"
     ]
    }
   ],
   "source": [
    "# Assurez-vous d'avoir un équilibre entre les bonnes et mauvaises requêtes\n",
    "sampled_bad = all_data[all_data['label'] == 1]#.sample(n=10000, random_state=42)\n",
    "sampled_good = all_data[all_data['label'] == 0]#.sample(n=10000, random_state=42)\n",
    "\n",
    "# Combine les deux échantillons en un seul DataFrame\n",
    "balanced_sampled_data = pd.concat([sampled_bad, sampled_good])\n",
    "\n",
    "# Mélangez les données pour éviter toute séquence qui pourrait influencer l'apprentissage\n",
    "balanced_sampled_data = balanced_sampled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Affichage des nouvelles dimensions du DataFrame équilibré\n",
    "print(\"Shape of balanced sampled data:\", balanced_sampled_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Étape 2 : Préparation des données\n",
    "\n",
    "Nous diviserons les données en ensembles d'entraînement et de test, puis appliquerons la vectorisation TF-IDF pour convertir les requêtes textuelles en vecteurs numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_sampled_data['query'], balanced_sampled_data['label'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation TF-IDF\n",
    "\n",
    "#X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "#X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1er modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/mamba/lib/python3.12/site-packages (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/mamba/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/mamba/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/mamba/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour adapter `vocab_size` et `max_length` dans votre modèle CNN pour la classification de texte, voici quelques considérations et méthodes que vous pouvez utiliser :\n",
    "\n",
    "### 1. **Déterminer `max_length`**\n",
    "`max_length` est la longueur maximale d'une séquence de texte (en mots ou tokens) que votre réseau traitera. Voici comment choisir cette valeur :\n",
    "\n",
    "- **Analyse des données** : Commencez par analyser la distribution des longueurs de vos textes. Vous pouvez le faire en calculant la longueur de chaque texte et en utilisant des statistiques descriptives ou des visualisations comme un histogramme.\n",
    "- **Choix basé sur la distribution** : Souvent, on choisit une valeur qui couvre une grande partie de l'ensemble de données, par exemple, la 90ème ou 95ème percentile de la distribution des longueurs. Cela garantit que la majorité des textes sont traités sans trop de troncature tout en évitant l'effet de quelques valeurs extrêmes très longues.\n",
    "  \n",
    "Exemple en Python pour calculer le percentile de la longueur des textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% des textes ont une longueur de 73 mots ou moins.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calcul des longueurs de texte\n",
    "text_lengths = [len(text.split()) for text in X_train]\n",
    "\n",
    "# Calcul du 95ème percentile\n",
    "max_length = int(np.percentile(text_lengths, 100))\n",
    "\n",
    "print(\"100% des textes ont une longueur de\", max_length, \"mots ou moins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1207103                                           /volo02-a/\n",
      "960768                               /image0021083316404294/\n",
      "291482     /7dbjwpw6.asp?<img src=\"javascript:alert(cross...\n",
      "60772                                               /776171/\n",
      "446819                                            /93218228/\n",
      "201782                                           /000045336/\n",
      "1075655                                          /000118644/\n",
      "819209                                /software della poker/\n",
      "1111199                          /ugress - cowboy desperado/\n",
      "2684                                     /seinfeld s4e13-18/\n",
      "Name: query, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Afficher les 10 premières requêtes de X_train\n",
    "print(X_train.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% des textes ont une longueur de 2.0 mots ou moins.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calcul des longueurs de chaque texte\n",
    "text_lengths = [len(text.split()) for text in X_train]\n",
    "\n",
    "# Création de l'histogramme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(text_lengths, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution des longueurs de texte dans X_train')\n",
    "plt.xlabel('Longueur du texte')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Pour calculer le 95ème percentile de ces longueurs\n",
    "percentile_95 = np.percentile(text_lengths, 95)\n",
    "print(f\"95% des textes ont une longueur de {percentile_95} mots ou moins.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Déterminer `vocab_size`**\n",
    "`vocab_size` est le nombre de mots uniques dans votre corpus qui seront considérés par le modèle. Voici comment le définir :\n",
    "\n",
    "- **Calcul du vocabulaire** : Utilisez vos données d'entraînement pour déterminer combien de mots uniques existent.\n",
    "- **Choix de `vocab_size`** : Vous pourriez vouloir limiter ce nombre pour réduire la complexité du modèle et éviter l'overfitting. Un choix courant est de garder seulement les mots les plus fréquents, ce qui peut être effectué en utilisant un tokenizer ou un vectoriseur qui supporte cette fonctionnalité.\n",
    "- **Utilisation de Tokenizer de Keras** : Keras offre un outil pratique, `Tokenizer`, qui peut automatiquement gérer le vocabulaire et convertir les textes en séquences de mots. Vous pouvez le configurer pour utiliser uniquement les mots les plus fréquents.\n",
    "\n",
    "Exemple en Python pour ajuster `vocab_size` :\n",
    "```python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Initialisation du tokenizer avec une taille de vocabulaire limitée\n",
    "tokenizer = Tokenizer(num_words=20000)  # Supposons que vous voulez garder les 20,000 mots les plus fréquents\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Vous pouvez maintenant utiliser tokenizer pour convertir les textes en séquences\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# Accédez au dictionnaire de mots\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique tokens.')\n",
    "```\n",
    "\n",
    "Dans cet exemple, `num_words` dans `Tokenizer` contrôle la taille maximale du vocabulaire utilisé pour vectoriser les textes. Les mots au-delà de cette limite seront ignorés. Cela aide à gérer l'efficacité de la mémoire et à réduire le bruit potentiel de mots très rares dans la formation du modèle.\n",
    "\n",
    "En résumé, la détermination de `vocab_size` et `max_length` doit être faite de manière stratégique, basée sur une analyse de vos données spécifiques. Une bonne pratique consiste à expérimenter avec différentes valeurs pour voir leur impact sur les performances du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 08:04:17.655279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 08:04:25.630924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Étendre le vocabulaire\n",
    "tokens = ['/', '<', '>', 'script', 'alert', 'http', '.exe', '.jpg', '=', 'select', 'drop', '--', '%', '..\\\\']\n",
    "\n",
    "# Créer le tokenizer avec un vocabulaire plus large et configurer pour n-grams\n",
    "tokenizer = Tokenizer(num_words=len(tokens), filters='', lower=False, split=' ', char_level=False, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(tokens)  # Mettre à jour l'index avec ces tokens\n",
    "\n",
    "# Exemple de données avec des tokens potentiellement malveillants\n",
    "example_data = [\n",
    "    \"/examples/jsp/cal/search.php?allwords=<br><script>foo</script>&cid=0&title=1&desc=1\",\n",
    "    \"/moodle/filter/tex/texed.php?formdata=foo&pathname=foo\\\"+||+echo+db+4d+5a+50+00+02+00+00+00+04+00+0f+00+ff+ff+00+00+b8+00+00+00+00+00+00+00+40++>>esbq\"\n",
    "]\n",
    "\n",
    "# Tokenisation et padding des séquences\n",
    "sequences = tokenizer.texts_to_sequences(example_data)\n",
    "data = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "print(data)  # Affiche les séquences de données prêtes pour un modèle de réseau de neurones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: [[8, 9, 10, 11, 4, 12, 13, 5, 3, 5, 14, 15, 16, 6, 17, 6], [18, 19, 20, 21, 4, 22, 3, 23, 3, 24, 25, 26, 27, 28, 2, 29, 2, 2, 2, 30, 2, 31, 2, 7, 7, 2, 2, 32, 2, 2, 2, 2, 2, 2, 2, 33, 34]]\n",
      "Padded Sequences: [[ 8  9 10 11  4 12 13  5  3  5 14 15 16  6 17  6  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [18 19 20 21  4 22  3 23  3 24 25 26 27 28  2 29  2  2  2 30  2 31  2  7\n",
      "   7  2  2 32  2  2  2  2  2  2  2 33 34]]\n",
      "Word Index: {'<OOV>': 1, '00': 2, 'foo': 3, 'php': 4, 'script': 5, '1': 6, 'ff': 7, 'examples': 8, 'jsp': 9, 'cal': 10, 'search': 11, 'allwords': 12, 'br': 13, 'cid': 14, '0': 15, 'title': 16, 'desc': 17, 'moodle': 18, 'filter': 19, 'tex': 20, 'texed': 21, 'formdata': 22, 'pathname': 23, 'echo': 24, 'db': 25, '4d': 26, '5a': 27, '50': 28, '02': 29, '04': 30, '0f': 31, 'b8': 32, '40': 33, 'esbq': 34}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Création du tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')  # 'num_words' est le nombre max de mots à garder\n",
    "\n",
    "# Exemple de données\n",
    "example_data = [\n",
    "    \"/examples/jsp/cal/search.php?allwords=<br><script>foo</script>&cid=0&title=1&desc=1\",\n",
    "    \"/moodle/filter/tex/texed.php?formdata=foo&pathname=foo\\\"+||+echo+db+4d+5a+50+00+02+00+00+00+04+00+0f+00+ff+ff+00+00+b8+00+00+00+00+00+00+00+40++>>esbq\"\n",
    "]\n",
    "\n",
    "# Adapter le tokenizer aux données\n",
    "tokenizer.fit_on_texts(example_data)\n",
    "sequences = tokenizer.texts_to_sequences(example_data)\n",
    "padded = pad_sequences(sequences, padding='post')  # 'post' signifie que le padding est ajouté à la fin\n",
    "\n",
    "print(\"Sequences:\", sequences)\n",
    "print(\"Padded Sequences:\", padded)\n",
    "print(\"Word Index:\", tokenizer.word_index)  # Affiche le dictionnaire des mots indexés\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 08:04:56.030156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:af:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "# Supposons que tokenizer a déjà été créé et formé\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# Padding des séquences pour avoir la même longueur\n",
    "data = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Définition de vocab_size basé sur le tokenizer\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 pour le token OOV si utilisé\n",
    "\n",
    "# Définir embedding_dim, par exemple à 100\n",
    "embedding_dim = 100\n",
    "\n",
    "# Calcul ou définition de max_length, vous pouvez utiliser un percentile comme décrit précédemment\n",
    "max_length = 150  # Supposons que vous avez choisi ce nombre basé sur l'analyse de la distribution des longueurs\n",
    "\n",
    "# Modèle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715933100.317334     895 service.cc:145] XLA service 0x7f5c500016c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1715933100.317411     895 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-05-17 08:05:00.559045: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-17 08:05:01.206484: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m    7/33565\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10:02\u001b[0m 18ms/step - accuracy: 0.9251 - loss: 0.5998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715933103.915149     895 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 15ms/step - accuracy: 0.9943 - loss: 0.0225\n",
      "Epoch 2/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 15ms/step - accuracy: 0.9972 - loss: 0.0118\n",
      "Epoch 3/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 15ms/step - accuracy: 0.9973 - loss: 0.0112\n",
      "Epoch 4/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0107\n",
      "Epoch 5/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0102\n",
      "Epoch 6/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0102\n",
      "Epoch 7/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0100\n",
      "Epoch 8/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0099\n",
      "Epoch 9/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m529s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0103\n",
      "Epoch 10/10\n",
      "\u001b[1m33565/33565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f66cefc8cb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supposons que 'data' est votre matrice de features et 'y_train' vos labels\n",
    "model.fit(data, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 16ms/step - accuracy: 0.9936 - loss: 0.0237\n",
      "Epoch 2/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 16ms/step - accuracy: 0.9971 - loss: 0.0119\n",
      "Epoch 3/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0112\n",
      "Epoch 4/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 16ms/step - accuracy: 0.9974 - loss: 0.0109\n",
      "Epoch 5/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0104\n",
      "Epoch 6/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0102\n",
      "Epoch 7/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0103\n",
      "Epoch 8/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0101\n",
      "Epoch 9/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0100\n",
      "Epoch 10/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9978 - loss: 0.0093\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 16ms/step - accuracy: 0.9937 - loss: 0.0245\n",
      "Epoch 2/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9971 - loss: 0.0120\n",
      "Epoch 3/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0110\n",
      "Epoch 4/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9974 - loss: 0.0109\n",
      "Epoch 5/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0103\n",
      "Epoch 6/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0096\n",
      "Epoch 7/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0101\n",
      "Epoch 8/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0097\n",
      "Epoch 9/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0101\n",
      "Epoch 10/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0100\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 16ms/step - accuracy: 0.9937 - loss: 0.0236\n",
      "Epoch 2/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 16ms/step - accuracy: 0.9970 - loss: 0.0121\n",
      "Epoch 3/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0113\n",
      "Epoch 4/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0105\n",
      "Epoch 5/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 16ms/step - accuracy: 0.9975 - loss: 0.0104\n",
      "Epoch 6/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0097\n",
      "Epoch 7/10\n",
      "\u001b[1m26852/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0098\n",
      "Epoch 8/10\n",
      "\u001b[1m24036/26852\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m44s\u001b[0m 16ms/step - accuracy: 0.9977 - loss: 0.0094"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "# Assurez-vous que 'data' et 'y_train' sont des numpy arrays\n",
    "data_array = np.array(data)\n",
    "y_train_array = np.array(y_train)\n",
    "\n",
    "# Exemple de boucle de validation croisée avec les modifications\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "times_per_fold = []\n",
    "\n",
    "for train, test in kfold.split(data_array, y_train_array):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "        Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Début du chronomètre\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Entraînement\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    model.fit(data_array[train], y_train_array[train], batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "    # Évaluation du modèle\n",
    "    scores = model.evaluate(data_array[test], y_train_array[test], verbose=0)\n",
    "\n",
    "    # Fin du chronomètre\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    times_per_fold.append(elapsed_time)\n",
    "\n",
    "    # Stockage des scores\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "# Affichage des résultats\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(len(acc_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - Time: {times_per_fold[i]:.2f} sec')\n",
    "print('------------------------------------------------------------------------')\n",
    "print(f'Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> Average Time per Fold: {np.mean(times_per_fold):.2f} sec')\n",
    "print('------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Représentation du modèle de réseau de neurones\n",
    "\n",
    "```plaintext\n",
    "+------------------------------------------------------+\n",
    "|                       Input                          |\n",
    "|                                                      |\n",
    "|  [input_dim=vocab_size, input_length=max_length]     |\n",
    "+------------------------------------------------------+\n",
    "                            |\n",
    "                            v\n",
    "+------------------------------------------------------+\n",
    "|                   Embedding Layer                    |\n",
    "|                                                      |\n",
    "|       [output_dim=embedding_dim, input_length=max_length]  |\n",
    "+------------------------------------------------------+\n",
    "                            |\n",
    "                            v\n",
    "+------------------------------------------------------+\n",
    "|                    Conv1D Layer                      |\n",
    "|                                                      |\n",
    "|       [filters=128, kernel_size=5, activation='relu']|\n",
    "+------------------------------------------------------+\n",
    "                            |\n",
    "                            v\n",
    "+------------------------------------------------------+\n",
    "|               GlobalMaxPooling1D Layer               |\n",
    "+------------------------------------------------------+\n",
    "                            |\n",
    "                            v\n",
    "+------------------------------------------------------+\n",
    "|                    Dense Layer                       |\n",
    "|                                                      |\n",
    "|               [units=1, activation='sigmoid']        |\n",
    "+------------------------------------------------------+\n",
    "                            |\n",
    "                            v\n",
    "+------------------------------------------------------+\n",
    "|                      Output                          |\n",
    "+------------------------------------------------------+\n",
    "```\n",
    "\n",
    "### Description des couches :\n",
    "\n",
    "1. **Input Layer**: Reçoit une séquence de longueur `max_length` avec un vocabulaire de taille `vocab_size`.\n",
    "2. **Embedding Layer**: Transforme les indices de mots en vecteurs d'embeddings de dimension `embedding_dim`.\n",
    "3. **Conv1D Layer**: Applique une convolution 1D avec `128` filtres de taille `5` et utilise la fonction d'activation ReLU.\n",
    "4. **GlobalMaxPooling1D Layer**: Effectue une réduction maximale sur toute la séquence, conservant les caractéristiques les plus importantes.\n",
    "5. **Dense Layer**: C'est une couche complètement connectée avec une unité de sortie et une fonction d'activation sigmoïde pour produire une probabilité.\n",
    "\n",
    "Ce diagramme et cette description devraient fournir une représentation claire et académique du réseau de neurones que tu as décrit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats de la validation croisée que vous avez obtenus sont très encourageants. Avec une précision moyenne de 97.36% et une très faible variation (écart-type de 0.22%), votre modèle semble bien généraliser sur différentes partitions de vos données. Voici quelques points à considérer et des étapes possibles pour améliorer encore ou valider davantage votre modèle :\n",
    "\n",
    "### Analyse des Résultats\n",
    "1. **Stabilité du Modèle** : La faible variation dans les scores de précision indique que le modèle est stable à travers différents sous-ensembles de données, ce qui est un signe positif de sa capacité à généraliser.\n",
    "2. **Consistance de la Perte** : La perte moyenne est également assez faible et constante à travers les plis, ce qui suggère que le modèle ne souffre pas de surapprentissage significatif.\n",
    "\n",
    "### Étapes Suivantes\n",
    "1. **Examen des Erreurs** : Analysez les cas où le modèle fait des erreurs pour voir s'il y a des patterns spécifiques ou des types de données sur lesquels il ne performe pas bien.\n",
    "2. **Optimisation des Hyperparamètres** : Bien que les résultats soient déjà excellents, vous pourriez explorer l'optimisation des hyperparamètres pour voir si de légers ajustements peuvent améliorer encore les performances. Cela peut inclure l'ajustement de la taille des embeddings, la modification des tailles de filtres ou des couches dans le modèle CNN, ou l'expérimentation avec différents optimiseurs ou taux d'apprentissage.\n",
    "3. **Validation Externe** : Si possible, testez le modèle sur un ensemble de données externe qui n'a pas été utilisé pendant l'entraînement ou la validation croisée pour évaluer sa robustesse dans des conditions réelles.\n",
    "4. **Augmentation de Données** : Pour les tâches de traitement du texte, notamment dans le contexte de la sécurité ou des requêtes HTTP, l'augmentation des données (par exemple, par la génération synthétique de données textuelles similaires) pourrait aider à améliorer la robustesse du modèle.\n",
    "\n",
    "### Considérations Finales\n",
    "- **Interprétabilité** : Si c'est important pour votre application, envisagez des techniques pour rendre le modèle plus interprétable, comme l'analyse des poids de la couche d'embedding ou l'utilisation de techniques telles que LIME ou SHAP pour expliquer les prédictions.\n",
    "- **Déploiement** : Planifiez le déploiement du modèle, ce qui peut inclure l'intégration à des systèmes existants, la surveillance de la performance en production, et l'établissement de pipelines pour la mise à jour régulière du modèle avec de nouvelles données.\n",
    "\n",
    "Ces scores montrent que vous avez un modèle solide pour votre tâche de classification, et ces étapes vous aideront à l'optimiser et à le préparer pour un déploiement efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examiner les erreurs qu'un modèle de machine learning fait pendant le test ou la validation est crucial pour comprendre ses limites et pour identifier des pistes d'amélioration. Voici une approche en plusieurs étapes pour examiner les erreurs de votre modèle de classification de texte, en utilisant les données et les prédictions :\n",
    "\n",
    "### 1. **Collecter les Prédictions et les Vraies Étiquettes**\n",
    "D'abord, assurez-vous de collecter les prédictions de votre modèle ainsi que les vraies étiquettes des données sur lesquelles il a été testé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(data[test])\n",
    "predicted_labels = (predictions > 0.5).astype(int)  # Seuil de 0.5 pour la classification binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Comparer les Prédictions aux Vraies Étiquettes**\n",
    "Ensuite, comparez les prédictions aux vraies étiquettes pour identifier où le modèle se trompe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_indices = np.where(predicted_labels.flatten() != y_train_array[test])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in incorrect_indices:\n",
    "    print(f\"Text: {X_train.iloc[test[index]]}\")  # Assurez-vous que c'est correct pour l'accès à X_train\n",
    "    print(f\"Predicted Label: {predicted_labels[index][0]}\")\n",
    "    print(f\"True Label: {y_train_array[test[index]]}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Analyse des Erreurs**\n",
    "Pour chaque instance mal classifiée, examinez le texte, la prédiction du modèle, et la vraie étiquette. Cela peut vous aider à identifier des patterns ou des types de textes spécifiques pour lesquels le modèle ne performe pas bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assurez-vous d'avoir `y_train_array` disponible comme numpy array\n",
    "true_labels = y_train_array[test]  # Utilisez les vraies étiquettes pour l'ensemble de test\n",
    "cm = confusion_matrix(true_labels, predicted_labels.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour une meilleure visualisation\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=['Good', 'Bad'], yticklabels=['Good', 'Bad'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour identifier spécifiquement les instances où le modèle a prédit à tort des valeurs positives (dans votre cas, classifiant à tort des requêtes comme \"bonnes\" alors qu'elles étaient en réalité des \"mauvaises requêtes\"), vous pouvez suivre les étapes suivantes pour isoler ces cas et les examiner plus en détail. \n",
    "\n",
    "#### 1. **Obtenir les Indices des Erreurs de Type I (Faux Positifs)**\n",
    "Vous pouvez calculer les faux positifs en comparant les étiquettes prédites avec les vraies étiquettes. Utilisez les indices pour localiser les erreurs dans vos données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# predictions a déjà été généré par model.predict(data[test])\n",
    "predicted_labels = (predictions > 0.5).astype(int)  # Assurez-vous que cela est adapté à votre seuil\n",
    "\n",
    "# Assurez-vous d'avoir `y_train_array` comme numpy array\n",
    "true_labels = y_train_array[test]  # Utilisez les vraies étiquettes de l'ensemble de test\n",
    "\n",
    "# Trouver les indices des faux positifs\n",
    "false_positives = np.where((predicted_labels.flatten() == 1) & (true_labels == 0))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **Extraire les Requêtes Correspondantes**\n",
    "Avec les indices des faux positifs, vous pouvez extraire les requêtes HTTP correspondantes de votre ensemble de test pour les examiner. Cela nécessite que `X_train` ou l'ensemble de données original soit accessible et correctement aligné avec `data[test]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assurez-vous que X_train est accessible et que son indexation est correcte\n",
    "false_positive_texts = X_train.iloc[test[false_positives]]  # Utilisez iloc si X_train est un DataFrame\n",
    "\n",
    "# Afficher les textes mal classifiés\n",
    "print(\"Faux Positifs (Good requests prises pour des Bad requests) :\")\n",
    "for i, text in enumerate(false_positive_texts):\n",
    "    print(f\"{i + 1}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 3. **Analyse des Textes Faux Positifs**\n",
    "Une fois que vous avez identifié les requêtes mal classifiées, vous pouvez :\n",
    "\n",
    "- **Revoir le Contenu** : Examinez le contenu des requêtes pour identifier des caractéristiques communes ou des motifs qui pourraient avoir trompé le modèle.\n",
    "- **Considérer le Contexte** : Pensez au contexte ou à la structure spécifique des requêtes qui pourrait être mal interprétée par le modèle.\n",
    "\n",
    "#### 4. **Amélioration du Modèle**\n",
    "En fonction de vos observations, vous pourriez envisager des ajustements tels que :\n",
    "\n",
    "- **Amélioration de la Préparation des Données** : Ajoutez un nettoyage plus spécifique ou des transformations pour mieux capter les caractéristiques des \"bad requests\".\n",
    "- **Entraînement Supplémentaire** : Entraînez le modèle avec plus de données, en particulier en augmentant les exemples de \"bad requests\" similaires à ceux mal classifiés.\n",
    "- **Ajustement de l'Architecture du Modèle** : Modifiez le modèle pour mieux capturer les caractéristiques pertinentes, ou ajoutez des couches de régularisation si le modèle surajuste certaines caractéristiques non pertinentes.\n",
    "\n",
    "En suivant ces étapes, vous pourrez non seulement identifier les erreurs spécifiques de votre modèle mais également prendre des mesures informées pour améliorer sa performance générale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour identifier spécifiquement les instances où votre modèle a prédit incorrectement des valeurs négatives alors qu'elles étaient positives (dans votre contexte, cela signifierait que des \"bad requests\" ont été faussement classifiées comme \"good requests\"), vous pouvez suivre une approche similaire à celle utilisée pour les faux positifs mais inverser la logique pour détecter les faux négatifs.\n",
    "\n",
    "### Étapes pour identifier les faux négatifs:\n",
    "\n",
    "1. **Calcul des Faux Négatifs**:\n",
    "   Utilisez les prédictions et les vraies étiquettes pour identifier où le modèle a prédit '0' (négatif) alors que la vraie étiquette était '1' (positif).\n",
    "\n",
    "2. **Extraire les Textes Correspondants**:\n",
    "   Utilisez les indices obtenus pour extraire les requêtes correspondantes de votre ensemble de données.\n",
    "\n",
    "### Code pour les faux négatifs:\n",
    "\n",
    "Assurez-vous que `predictions`, `y_train_array`, et `test` sont définis comme expliqué précédemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prédiction à partir du modèle, assurez-vous que cela est déjà fait\n",
    "predicted_labels = (predictions > 0.5).astype(int)  # Appliquer un seuil de 0.5 pour la classification binaire\n",
    "\n",
    "# Calculer les indices des faux négatifs\n",
    "false_negatives = np.where((predicted_labels.flatten() == 0) & (y_train_array[test] == 1))[0]\n",
    "\n",
    "# Supposons que X_train est un DataFrame Pandas accessible et que les indices sont alignés\n",
    "# Si X_train est sous forme de numpy array ou list, assurez-vous d'utiliser la méthode d'accès correcte\n",
    "false_negative_texts = X_train.iloc[test[false_negatives]]\n",
    "\n",
    "# Afficher les textes mal classifiés\n",
    "print(\"Faux Négatifs (Bad requests classifiées comme Good) :\")\n",
    "for i, text in enumerate(false_negative_texts):\n",
    "    print(f\"{i + 1}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Explications:\n",
    "- **`np.where()`**: Cette fonction est utilisée pour trouver les indices des éléments qui satisfont la condition spécifiée, ici étant les cas où les prédictions ne correspondent pas aux étiquettes attendues et où les vraies étiquettes sont positives ('1').\n",
    "- **`predicted_labels.flatten()`**: Assure que le tableau de prédictions est une dimension pour correspondre avec le tableau de vraies étiquettes.\n",
    "- **`X_train.iloc[test[false_negatives]]`**: Extrayez les textes spécifiques de `X_train` qui correspondent aux indices des faux négatifs. Assurez-vous que l'indexation de `X_train` est correctement configurée pour cela.\n",
    "\n",
    "Cette approche vous permettra d'examiner les cas où des requêtes malicieuses ou incorrectes (bad requests) ont été incorrectement classifiées comme légitimes (good requests), vous aidant ainsi à identifier les lacunes potentielles dans le modèle ou les données qui nécessitent une attention particulière."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ces faux négatifs sont des erreurs critiques, surtout dans le contexte de la sécurité des systèmes, car ils représentent des menaces potentielles qui ne sont pas identifiées.\n",
    "\n",
    "### Analyse des Faux Négatifs\n",
    "Les exemples montrent une variété de patterns typiques des attaques ou des tentatives de manipulation, telles que :\n",
    "- Injections SQL ou de commandes (`rm`, `del`).\n",
    "- Utilisation de caractères spéciaux et d'encodages pour masquer des tentatives malveillantes (`%00`, `../`, `</`).\n",
    "- Noms qui suggèrent des tentatives d'accès à des ressources sensibles ou des scripts (`script`, `transcript`, `ini`).\n",
    "\n",
    "### Étapes pour améliorer la détection\n",
    "1. **Amélioration de la Tokenisation** :\n",
    "   - Revisez votre `custom_tokenizer` pour vous assurer qu'il capture efficacement les éléments importants qui indiquent des requêtes malveillantes. Par exemple, vous voudrez peut-être capturer des séquences de caractères spécifiques qui apparaissent souvent dans les attaques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Étendre le vocabulaire\n",
    "tokens = ['/', '<', '>', 'script', 'alert', 'http', '.exe', '.jpg', '=', 'select', 'drop', '--', '%', '..\\\\']\n",
    "\n",
    "# Créer le tokenizer avec un vocabulaire plus large et configurer pour n-grams\n",
    "tokenizer = Tokenizer(num_words=len(tokens), filters='', lower=False, split=' ', char_level=False, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(tokens)  # Mettre à jour l'index avec ces tokens\n",
    "\n",
    "# Exemple de données avec des tokens potentiellement malveillants\n",
    "example_data = [\n",
    "    \"/examples/jsp/cal/search.php?allwords=<br><script>foo</script>&cid=0&title=1&desc=1\",\n",
    "    \"/moodle/filter/tex/texed.php?formdata=foo&pathname=foo\\\"+||+echo+db+4d+5a+50+00+02+00+00+00+04+00+0f+00+ff+ff+00+00+b8+00+00+00+00+00+00+00+40++>>esbq\"\n",
    "]\n",
    "\n",
    "# Tokenisation et padding des séquences\n",
    "sequences = tokenizer.texts_to_sequences(example_data)\n",
    "data = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "print(data)  # Affiche les séquences de données prêtes pour un modèle de réseau de neurones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Enrichissement des Données** :\n",
    "   - Si possible, enrichissez votre ensemble de données avec plus d'exemples de ce type de requêtes malveillantes, surtout ceux qui sont mal classifiés.\n",
    "   - Utilisez des techniques d'augmentation de données pour créer de nouvelles instances d'entraînement basées sur les modèles trouvés dans les faux négatifs.\n",
    "\n",
    "\n",
    "NON FAIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Réévaluation des Features** :\n",
    "   - Examinez les caractéristiques (features) extraites par le `TfidfVectorizer` et considérez l'ajustement des paramètres comme `ngram_range` pour capturer des motifs plus larges ou plus complexes.\n",
    "   - Envisagez l'utilisation d'embeddings de mots plus sophistiqués qui pourraient capturer le contexte mieux que les simples TF-IDF.\n",
    "  \n",
    "\n",
    "NON FAIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Réglage du Modèle** :\n",
    "   - Ajustez les seuils de classification pour le modèle afin de réduire le taux de faux négatifs, ce qui peut être particulièrement important si éviter les mauvaises classifications est plus critique que de capturer chaque bonne requête.\n",
    "   - Testez différentes architectures de modèle ou introduisez des techniques comme le bagging ou le boosting pour voir si cela améliore la robustesse du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Utilisation de Techniques de Détection Anomale** :\n",
    "   - Pour les requêtes qui ne s'inscrivent pas clairement dans les patterns normaux mais qui sont également difficiles à classer directement comme malveillantes, envisagez des techniques de détection d'anomalies.\n",
    "\n",
    "Ces étapes devraient aider à améliorer la capacité de votre modèle à identifier correctement les mauvaises requêtes, en réduisant le nombre de faux négatifs et en augmentant la sécurité globale du système que vous cherchez à protéger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Analyse Qualitative et Quantitative**\n",
    "- **Qualitative** : Lisez les textes que le modèle a mal classifiés pour voir s'il y a des caractéristiques communes, comme des erreurs d'orthographe, des abréviations, des structures grammaticales complexes, etc.\n",
    "- **Quantitative** : Analysez statistiquement les types d'erreurs. Par exemple, regardez si certaines classes sont plus sujettes aux erreurs ou si certains types de requêtes sont systématiquement mal classés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Visualisation des Erreurs**\n",
    "Utiliser des visualisations comme des matrices de confusion pour mieux comprendre les types d'erreurs (par exemple, quelle classe est souvent confondue avec quelle autre) :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. **Feedback Loop**\n",
    "Utilisez ces informations pour affiner votre modèle. Cela peut impliquer l'ajustement de la préparation des données, la modification des paramètres du modèle, ou même la reformulation de la façon dont les données sont présentées au modèle.\n",
    "\n",
    "L'examen des erreurs est un processus continu qui peut nécessiter plusieurs itérations pour isoler et résoudre les problèmes sous-jacents. C'est aussi une excellente opportunité pour découvrir des améliorations potentielles non seulement dans le modèle, mais aussi dans la collecte ou le traitement des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des résultats selon le Tokenizer\n",
    "\n",
    "Le modèle 1 dans good_bad_CNN.ipynb :"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Score per fold\n",
    "> Fold 1 - Loss: 0.13836640119552612 - Accuracy: 97.12499976158142%\n",
    "> Fold 2 - Loss: 0.11552897095680237 - Accuracy: 97.40625023841858%\n",
    "> Fold 3 - Loss: 0.13169389963150024 - Accuracy: 97.03124761581421%\n",
    "> Fold 4 - Loss: 0.1650751531124115 - Accuracy: 96.78124785423279%\n",
    "> Fold 5 - Loss: 0.13054288923740387 - Accuracy: 97.3437488079071%\n",
    "------------------------------------------------------------------------\n",
    "Average scores for all folds:\n",
    "> Accuracy: 97.13749885559082 (+- 0.2250007457214422)\n",
    "> Loss: 0.13624146282672883\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Tokenizer amélioré ici:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Score per fold\n",
    "> Fold 1 - Loss: 0.10068336129188538 - Accuracy: 97.3437488079071% - Time: 11.00 sec\n",
    "> Fold 2 - Loss: 0.11529579758644104 - Accuracy: 97.71875143051147% - Time: 10.75 sec\n",
    "> Fold 3 - Loss: 0.11323544383049011 - Accuracy: 97.31249809265137% - Time: 10.89 sec\n",
    "> Fold 4 - Loss: 0.11450822651386261 - Accuracy: 97.21875190734863% - Time: 11.53 sec\n",
    "> Fold 5 - Loss: 0.12105467170476913 - Accuracy: 97.65625% - Time: 10.84 sec\n",
    "------------------------------------------------------------------------\n",
    "Average scores for all folds:\n",
    "> Accuracy: 97.45000004768372 (+- 0.19921755173805408)\n",
    "> Loss: 0.11295550018548965\n",
    "> Average Time per Fold: 11.00 sec\n",
    "------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellents résultats! Vous observez une amélioration avec votre tokenizer optimisé, montrant une précision élevée et stable à travers les différents plis de la validation croisée. Pour explorer encore plus loin et améliorer la robustesse et la performance de votre modèle, vous pouvez en effet envisager d'expérimenter avec différentes architectures et d'introduire des techniques d'ensemble comme le bagging ou le boosting. Voici comment vous pourriez procéder :\n",
    "\n",
    "### 1. **Tester Différentes Architectures de Modèle**\n",
    "\n",
    "Vous pouvez expérimenter avec différentes configurations pour les couches de votre réseau neuronal, telles que :\n",
    "\n",
    "- **Augmenter le nombre de filtres dans les couches convolutives** : Plus de filtres peuvent permettre de capturer plus de caractéristiques fines du texte.\n",
    "- **Ajouter des couches convolutives** : Empiler plusieurs couches convolutives peut aider à apprendre des hiérarchies plus complexes de caractéristiques.\n",
    "- **Utiliser des tailles de noyau différentes** : Utiliser simultanément différentes tailles de noyaux dans les couches convolutives peut capter des motifs de différentes tailles dans les données.\n",
    "- **Inclure des couches de dropout** : Pour prévenir le surapprentissage en désactivant aléatoirement des neurones pendant l'entraînement.\n",
    "\n",
    "### 2. **Techniques d'Ensemble**\n",
    "\n",
    "- **Bagging** : Le bagging implique l'entraînement de multiples modèles (généralement du même type) sur différents sous-ensembles de l'ensemble de données d'entraînement et ensuite d'agréger leurs prédictions. Vous pouvez utiliser des variantes de votre modèle CNN avec différentes initialisations ou architectures et les combiner.\n",
    "  \n",
    "- **Boosting** : Techniques comme AdaBoost ou Gradient Boosting peuvent être utilisées mais sont moins communes pour les réseaux de neurones. Cependant, vous pouvez expérimenter avec des bibliothèques qui supportent ces méthodes adaptées aux réseaux de neurones, telles que CatBoost ou LightGBM pour des tâches de classification de features extraits.\n",
    "\n",
    "### 3. **Exemple d'Architecture avec Dropout et Plusieurs Couches Convolutives**\n",
    "\n",
    "Voici un exemple d'architecture plus complexe :\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
    "    Conv1D(filters=128, kernel_size=4, activation='relu'),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### 4. **Ajustement de l'Entraînement**\n",
    "\n",
    "En ajoutant des couches ou en modifiant l'architecture, il peut être nécessaire de revoir les paramètres d'entraînement tels que le taux d'apprentissage, le nombre d'époques, ou les tailles des lots.\n",
    "\n",
    "### 5. **Validation**\n",
    "\n",
    "Après avoir modifié l'architecture ou utilisé des techniques d'ensemble, il est crucial de réévaluer le modèle sur vos données de validation ou via la validation croisée pour s'assurer que les modifications apportent des améliorations significatives et ne conduisent pas à un surapprentissage.\n",
    "\n",
    "En résumé, expérimenter avec ces techniques peut potentiellement améliorer la robustesse de votre modèle et mieux généraliser sur de nouvelles données. Chaque modification doit être soigneusement validée pour évaluer son impact réel sur la performance du modèle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
