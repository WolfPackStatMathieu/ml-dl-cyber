{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour charger et préparer vos fichiers `badqueries.txt` et `goodqueries.txt` pour l'entraînement d'un modèle de machine learning avec Python et scikit-learn, vous pouvez suivre les étapes ci-dessous. Nous allons lire les fichiers, les étiqueter, les combiner en un seul dataframe, puis les préparer pour le processus d'apprentissage.\n",
    "\n",
    "### Étape 1 : Charger les données\n",
    "\n",
    "Assurez-vous que Python peut accéder aux fichiers où ils sont stockés sur votre système. Si nécessaire, ajustez le chemin d'accès aux fichiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Charger les données\n",
    "def load_data(filepath, label):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        data = [(line.strip(), label) for line in lines if line.strip()]\n",
    "    return data\n",
    "\n",
    "# Emplacements des fichiers\n",
    "bad_queries_path = 'badqueries.txt'\n",
    "good_queries_path = 'goodqueries.txt'\n",
    "\n",
    "# Charger et étiqueter les données\n",
    "bad_data = load_data(bad_queries_path, 1)  # Étiquette 1 pour les mauvaises requêtes\n",
    "good_data = load_data(good_queries_path, 0)  # Étiquette 0 pour les bonnes requêtes\n",
    "\n",
    "# Combinez les données dans un DataFrame\n",
    "all_data = pd.DataFrame(bad_data + good_data, columns=['query', 'label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Petite exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['query', 'label'], dtype='object')\n",
      "(1342596, 2)\n",
      "                                               query  label\n",
      "0                 /top.php?stuff='uname >q36497765 #      1\n",
      "1  /h21y8w52.nsf?<script>cross_site_scripting.nas...      1\n",
      "2  /ca000001.pl?action=showcart&hop=\\\"><script>al...      1\n",
      "3  /scripts/edit_image.php?dn=1&userfile=/etc/pas...      1\n",
      "4                                /javascript/mta.exe      1\n"
     ]
    }
   ],
   "source": [
    "print(all_data.columns)\n",
    "print(all_data.shape)\n",
    "print(all_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Étape 2 : Préparation des données\n",
    "\n",
    "Nous diviserons les données en ensembles d'entraînement et de test, puis appliquerons la vectorisation TF-IDF pour convertir les requêtes textuelles en vecteurs numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data['query'], all_data['label'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/' '00' '02' '04' '0f' '40' '4d' '50' '5a' '<' '=' '>' 'allwords' 'b8'\n",
      " 'br' 'cal' 'cid' 'db' 'desc' 'echo' 'esbq' 'examples' 'ff' 'filter' 'foo'\n",
      " 'formdata' 'jsp' 'moodle' 'pathname' 'php' 'script' 'search' 'tex'\n",
      " 'texed' 'title']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    # Utilisez une expression régulière pour considérer les mots et certains symboles spéciaux\n",
    "    token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b|\\/|<|>|script|alert|http|\\.exe|\\.jpg|=\")\n",
    "    return token_pattern.findall(text)\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=False, strip_accents=None)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "example_data = [\n",
    "    \"/examples/jsp/cal/search.php?allwords=<br><script>foo</script>&cid=0&title=1&desc=1\",\n",
    "    \"/moodle/filter/tex/texed.php?formdata=foo&pathname=foo\\\"+||+echo+db+4d+5a+50+00+02+00+00+00+04+00+0f+00+ff+ff+00+00+b8+00+00+00+00+00+00+00+40++>>esbq\"\n",
    "]\n",
    "\n",
    "X = vectorizer.fit_transform(example_data)\n",
    "print(vectorizer.get_feature_names_out())  # Affiche les termes du vocabulaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation TF-IDF\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comprendre à quoi ressemble `X_train_tfidf` après vectorisation avec TF-IDF, vous pouvez visualiser quelques aspects de cette matrice. `X_train_tfidf` est une matrice sparse (creuse) de `scikit-learn`, ce qui signifie qu'elle stocke uniquement les emplacements et les valeurs des éléments non nuls pour économiser de l'espace mémoire.\n",
    "\n",
    "### 1. Propriétés de base de la matrice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_tfidf: (1074076, 755132)\n",
      "Type of X_train_tfidf: <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)  # dimensions de la matrice\n",
    "print(\"Type of X_train_tfidf:\", type(X_train_tfidf))   # type de l'objet (sparse matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vérifier le nombre d'éléments non nuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero elements: 3318992\n",
      "Density of the matrix: 4.0921196018022575e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of non-zero elements:\", X_train_tfidf.nnz)\n",
    "print(\"Density of the matrix:\", X_train_tfidf.nnz / float(X_train_tfidf.shape[0] * X_train_tfidf.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Affichage des termes du vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some feature names: ['.exe' '.jpg' '/' '00' '000' '0000' '000000' '0000000' '00000000'\n",
      " '000000000' '00000000000000000020195001' '00000000000000097vascript'\n",
      " '000000000001' '0000000001' '0000000001_000000000000000051240'\n",
      " '0000000001_000000000000000122701' '000000000663' '000000000667'\n",
      " '000000000699' '000000000788']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Some feature names:\", feature_names[:20])  # affiche les 20 premiers termes du vocabulaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre mise en œuvre du `TfidfVectorizer` avec un tokenizer personnalisé semble bien adaptée pour gérer les requêtes potentiellement malveillantes que vous avez mentionnées. Vous avez bien configuré les étapes pour diviser vos données et appliquer la vectorisation TF-IDF, ce qui est crucial pour la suite de l'analyse avec un modèle de machine learning.\n",
    "\n",
    "### Points à considérer :\n",
    "1. **Validation du Tokenizer :** Assurez-vous que le tokenizer personnalisé extrait bien les termes pertinents de vos données d'entraînement et de test. Les termes imprimés depuis `example_data` donnent une bonne idée des tokens que votre vectorisateur considère.\n",
    "\n",
    "2. **Entraînement et transformation :** Vous avez utilisé `fit_transform` sur `X_train` et `transform` sur `X_test`, ce qui est la méthode correcte pour éviter la fuite de données de l'ensemble de test dans le modèle de vectorisation.\n",
    "\n",
    "3. **Gestion des caractères et motifs spéciaux :** Votre expression régulière semble bien conçue pour capturer à la fois les mots standards et les motifs spécifiques aux scripts malveillants, ce qui est essentiel pour ce type d'analyse.\n",
    "\n",
    "### Étapes suivantes :\n",
    "\n",
    "Maintenant que vos données sont prêtes, l'étape suivante consiste à choisir et entraîner un modèle de machine learning pour classifier les requêtes comme bonnes ou mauvaises. Voici quelques options de modèles que vous pourriez envisager :\n",
    "\n",
    "- **Régression logistique :** Un modèle simple mais efficace pour les tâches de classification binaire.\n",
    "- **Machines à vecteurs de support (SVM) :** Très efficace pour les espaces de grande dimension comme ceux créés par TF-IDF.\n",
    "- **Forêts aléatoires :** Bon pour gérer des données avec beaucoup de variance et pour capturer des non-linéarités sans trop de tuning nécessaire.\n",
    "- **Réseaux de neurones :** Si vous avez suffisamment de données et de ressources de calcul, un réseau de neurones pourrait capter des interactions complexes entre les mots.\n",
    "\n",
    "Chaque modèle a ses avantages et ses inconvénients, et le choix peut dépendre de la taille de vos données, de la précision requise, du temps de calcul disponible, et de votre familiarité avec les modèles.\n",
    "\n",
    "Si vous souhaitez des conseils sur l'entraînement d'un modèle spécifique ou sur l'évaluation de la performance du modèle, n'hésitez pas à demander !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9944212721584984\n",
      "Confusion Matrix:\n",
      " [[258575    446]\n",
      " [  1052   8447]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    259021\n",
      "           1       0.95      0.89      0.92      9499\n",
      "\n",
      "    accuracy                           0.99    268520\n",
      "   macro avg       0.97      0.94      0.96    268520\n",
      "weighted avg       0.99      0.99      0.99    268520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Création du modèle de régression logistique\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Entraînement du modèle avec les données d'entraînement\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prédiction des étiquettes sur l'ensemble de test\n",
    "y_pred = logreg.predict(X_test_tfidf)\n",
    "\n",
    "# Calcul et affichage des métriques de performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre modèle de régression logistique semble obtenir d'excellents résultats globalement, comme le montre la très haute précision globale (accuracy) de 99.44%. Cependant, il est toujours utile de regarder un peu plus en détail chaque métrique pour bien comprendre les performances du modèle, surtout dans le contexte de la classification de requêtes potentiellement malveillantes.\n",
    "\n",
    "### Analyse des Résultats\n",
    "\n",
    "1. **Précision globale (Accuracy) :** À 99.44%, la plupart des prédictions sont correctes. C'est une bonne indication que le modèle fonctionne bien en général.\n",
    "\n",
    "2. **Matrice de confusion :** \n",
    "   - **Vrais positifs pour la classe 0 (bonnes requêtes)** : 258575\n",
    "   - **Faux positifs pour la classe 0** : 446\n",
    "   - **Faux négatifs pour la classe 0** : 1052\n",
    "   - **Vrais positifs pour la classe 1 (mauvaises requêtes)** : 8447\n",
    "\n",
    "   Les faibles nombres de faux positifs et de faux négatifs suggèrent que le modèle est à la fois précis et sensible. Cependant, le nombre de faux négatifs est supérieur aux faux positifs, ce qui indique une légère faiblesse dans la capture de toutes les mauvaises requêtes (moins de sensibilité).\n",
    "\n",
    "3. **Rapport de classification :**\n",
    "   - **Précision pour la classe 0** : Pratiquement parfaite à 1.00.\n",
    "   - **Précision pour la classe 1** : À 0.95, c'est très bon, mais cela indique aussi que certains faux positifs sont présents.\n",
    "   - **Rappel pour la classe 0** : Aussi pratiquement parfait à 1.00.\n",
    "   - **Rappel pour la classe 1** : À 0.89, ce qui indique que le modèle manque environ 11% des mauvaises requêtes réelles.\n",
    "   - **F1-score pour la classe 1** : À 0.92, ce score équilibré entre précision et rappel est assez bon, mais peut être amélioré, surtout si l'identification précise des mauvaises requêtes est critique.\n",
    "\n",
    "### Suggestions pour l'amélioration\n",
    "\n",
    "- **Ajustement des hyperparamètres :** Vous pouvez tenter d'ajuster le paramètre de régularisation `C` de la régression logistique pour voir si une valeur plus faible (plus de régularisation) ou plus élevée (moins de régularisation) améliore les performances.\n",
    "\n",
    "- **Équilibrage des classes :** Si votre jeu de données est très déséquilibré, envisagez des techniques comme le rééchantillonnage (oversampling de la classe minoritaire ou undersampling de la classe majoritaire) ou l'utilisation de poids de classe dans le modèle de régression logistique pour donner plus de poids à la classe minoritaire pendant l'entraînement.\n",
    "\n",
    "- **Validation croisée :** Utiliser une validation croisée pour évaluer la robustesse du modèle sur différents sous-ensembles de vos données peut aider à garantir que les performances ne sont pas spécifiques à une division particulière des données.\n",
    "\n",
    "- **Essayer d'autres modèles :** Parfois, un modèle différent peut capturer les dynamiques des données plus efficacement. Les machines à vecteurs de support (SVM), les forêts aléatoires ou même un modèle de réseaux de neurones pourraient être testés pour comparer les performances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Les machines à vecteurs de support (SVM, pour Support Vector Machines) sont particulièrement efficaces pour les problèmes de classification à haute dimensionnalité, comme c'est souvent le cas avec les données textuelles transformées via TF-IDF. Les SVM sont bien connus pour leur capacité à créer une frontière de décision optimale (appelée hyperplan) qui maximise la marge entre les classes de données.\n",
    "\n",
    "Pour appliquer un SVM à vos données, vous pouvez utiliser la bibliothèque `scikit-learn`, qui offre une implémentation efficace à travers la classe `SVC` (C-Support Vector Classification). Voici comment vous pouvez mettre en œuvre et évaluer un SVM sur vos données:\n",
    "\n",
    "### 1. Importer les bibliothèques nécessaires\n",
    "Vous aurez besoin de `SVC` pour le modèle SVM et de quelques métriques pour évaluer les performances:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Création et entraînement du modèle SVM\n",
    "La création d'un modèle SVM avec des paramètres par défaut et son entraînement peut prendre du temps, surtout si la taille de l'ensemble des données est grande. Vous pouvez commencer avec les paramètres par défaut, puis ajuster selon les besoins:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prédiction et évaluation du modèle\n",
    "Après l'entraînement, utilisez le modèle pour faire des prédictions sur l'ensemble de test, puis évaluez les performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction des étiquettes sur l'ensemble de test\n",
    "# y_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# # Calcul et affichage des métriques de performance\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajustements possibles\n",
    "- **Kernel :** Le choix du noyau (`kernel`) est crucial. Les noyaux communs incluent `linear`, `poly`, `rbf`, `sigmoid`. Pour les données textuelles, `linear` est souvent un bon point de départ.\n",
    "- **C (paramètre de régularisation) :** Ajuster ce paramètre peut aider à contrôler le compromis entre l'atteinte d'une marge maximale et la minimisation de l'erreur de classification.\n",
    "- **gamma :** Ce paramètre définit l'influence d'un seul exemple d'entraînement, important surtout pour les noyaux non linéaires comme `rbf`.\n",
    "\n",
    "### Points à noter\n",
    "- **Scalabilité :** Les SVM peuvent ne pas être les plus rapides pour de très grands ensembles de données à cause de leur complexité de calcul. Dans ce cas, des stratégies comme réduire la taille de l'ensemble de données ou utiliser des versions plus simplifiées des SVM (comme LinearSVC) peuvent être envisagées.\n",
    "- **Interprétabilité :** Bien que très performants, les SVM ne fournissent pas une interprétabilité aussi directe que d'autres modèles (comme la régression logistique).\n",
    "\n",
    "N'hésitez pas à expérimenter avec ces paramètres pour optimiser les performances de votre modèle SVM sur votre problème spécifique. Si vous avez besoin d'aide pour ajuster ces paramètres ou pour comprendre leurs effets, je suis là pour aider !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mise en place de K-nearest neighbors\n",
    "KNN est un algorithme d'apprentissage supervisé simple et souvent efficace, qui prédit l'étiquette d'une donnée en se basant sur les étiquettes des \"K\" échantillons les plus proches dans l'espace des caractéristiques.\n",
    "\n",
    "### Considérations pour l'utilisation de KNN avec des données textuelles\n",
    "\n",
    "- **Dimensionnalité et performance** : KNN peut être moins efficace en termes de temps de calcul et de mémoire sur des ensembles de données de haute dimension, comme c'est souvent le cas avec les données textuelles transformées par TF-IDF. La réduction de dimension avec des techniques comme PCA (Principal Component Analysis) pourrait aider à améliorer les performances.\n",
    "- **Choix de K** : Le nombre de voisins, K, est un paramètre crucial. Un K trop petit peut rendre le modèle sensible au bruit, tandis qu'un K trop grand peut le rendre insensible aux structures réellement présentes dans les données. Il peut être utile de tester plusieurs valeurs de K pour trouver un bon équilibre.\n",
    "- **Métrique de distance** : La métrique utilisée pour calculer la distance entre les points est également importante. La distance euclidienne est standard, mais pour les données textuelles, d'autres métriques comme la distance de cosine pourraient parfois être plus appropriées.\n",
    "\n",
    "Expérimentez avec ces paramètres pour voir comment ils influencent les performances du modèle KNN sur vos données. Si vous avez besoin d'aide avec ces ajustements ou d'autres questions sur KNN, n'hésitez pas à demander !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oui, effectuer une réduction de dimension avant d'utiliser l'algorithme K-nearest neighbors (KNN) est une très bonne idée, surtout pour des données de haute dimension comme celles transformées par TF-IDF. La réduction de dimension peut améliorer significativement la performance de calcul de KNN et potentiellement aussi la qualité de la classification, en réduisant le bruit et en mettant en évidence les structures sous-jacentes des données.\n",
    "\n",
    "### Utilisation de PCA (Principal Component Analysis)\n",
    "\n",
    "Une méthode populaire de réduction de dimension est l'analyse en composantes principales (PCA), qui est souvent utilisée pour diminuer le nombre de dimensions tout en conservant le plus d'information possible. Voici comment vous pouvez appliquer PCA à vos données textuelles vectorisées avant de les utiliser pour KNN :\n",
    "\n",
    "1. **Importation des bibliothèques nécessaires** :\n",
    "   Vous aurez besoin de `PCA` de la bibliothèque `scikit-learn` ainsi que des autres composants utilisés précédemment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Application de PCA** :\n",
    "   Vous devrez choisir le nombre de composantes principales à conserver. Ce choix peut dépendre de la variabilité des données que vous souhaitez conserver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Création d'une instance de TruncatedSVD pour réduire à 100 dimensions\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "\n",
    "# Adapter TruncatedSVD aux données d'entraînement et les transformer\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "\n",
    "# Transformer également les données de test en utilisant le même transformateur\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Entraînement et évaluation du modèle KNN** :\n",
    "   Entraînez ensuite votre modèle KNN sur les données réduites.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Exemple de préparation des données\n",
    "X_train_tfidf_dense = np.array(X_train_tfidf.todense())  # Conversion de sparse à dense\n",
    "\n",
    "# Supposons que vous avez déjà divisé vos données:\n",
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "# Puis, par exemple pour un modèle RNN :\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model_rnn = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_tfidf_dense.shape[1],)),\n",
    "    LSTM(32),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_rnn.fit(X_train_tfidf_dense, y_train, epochs=10, batch_size=32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
