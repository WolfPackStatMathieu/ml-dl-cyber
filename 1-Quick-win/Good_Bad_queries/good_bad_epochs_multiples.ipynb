{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Étape 1 : Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/ml-dl-with-python/1-Quick-win/Good_Bad_queries\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Charger les données\n",
    "def load_data(filepath, label):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        data = [(line.strip(), label) for line in lines if line.strip()]\n",
    "    return data\n",
    "\n",
    "# Emplacements des fichiers\n",
    "bad_queries_path = 'badqueries.txt'\n",
    "good_queries_path = 'goodqueries.txt'\n",
    "\n",
    "# Charger et étiqueter les données\n",
    "bad_data = load_data(bad_queries_path, 1)  # Étiquette 1 pour les mauvaises requêtes\n",
    "good_data = load_data(good_queries_path, 0)  # Étiquette 0 pour les bonnes requêtes\n",
    "\n",
    "# Combinez les données dans un DataFrame\n",
    "all_data = pd.DataFrame(bad_data + good_data, columns=['query', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of balanced sampled data: (20000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Assurez-vous d'avoir un équilibre entre les bonnes et mauvaises requêtes\n",
    "sampled_bad = all_data[all_data['label'] == 1].sample(n=10000, random_state=42)\n",
    "sampled_good = all_data[all_data['label'] == 0].sample(n=10000, random_state=42)\n",
    "\n",
    "# Combine les deux échantillons en un seul DataFrame\n",
    "balanced_sampled_data = pd.concat([sampled_bad, sampled_good])\n",
    "\n",
    "# Mélangez les données pour éviter toute séquence qui pourrait influencer l'apprentissage\n",
    "balanced_sampled_data = balanced_sampled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Affichage des nouvelles dimensions du DataFrame équilibré\n",
    "print(\"Shape of balanced sampled data:\", balanced_sampled_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Étape 2 : Préparation des données\n",
    "\n",
    "Nous diviserons les données en ensembles d'entraînement et de test, puis appliquerons la vectorisation TF-IDF pour convertir les requêtes textuelles en vecteurs numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_sampled_data['query'], balanced_sampled_data['label'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/' '00' '02' '04' '0f' '40' '4d' '50' '5a' '<' '=' '>' 'allwords' 'b8'\n",
      " 'br' 'cal' 'cid' 'db' 'desc' 'echo' 'esbq' 'examples' 'ff' 'filter' 'foo'\n",
      " 'formdata' 'jsp' 'moodle' 'pathname' 'php' 'script' 'search' 'tex'\n",
      " 'texed' 'title']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    # Utilisez une expression régulière pour considérer les mots et certains symboles spéciaux\n",
    "    token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b|\\/|<|>|script|alert|http|\\.exe|\\.jpg|=\")\n",
    "    return token_pattern.findall(text)\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=False, strip_accents=None)\n",
    "\n",
    "# Exemple d'utilisation\n",
    "example_data = [\n",
    "    \"/examples/jsp/cal/search.php?allwords=<br><script>foo</script>&cid=0&title=1&desc=1\",\n",
    "    \"/moodle/filter/tex/texed.php?formdata=foo&pathname=foo\\\"+||+echo+db+4d+5a+50+00+02+00+00+00+04+00+0f+00+ff+ff+00+00+b8+00+00+00+00+00+00+00+40++>>esbq\"\n",
    "]\n",
    "\n",
    "X = vectorizer.fit_transform(example_data)\n",
    "print(vectorizer.get_feature_names_out())  # Affiche les termes du vocabulaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `custom_tokenizer` et la configuration du `TfidfVectorizer` dans votre code sont conçus pour traiter du texte de manière spécifique, en se focalisant particulièrement sur certaines caractéristiques des données textuelles. Voici une explication détaillée de chaque partie :\n",
    "\n",
    "### Fonction `custom_tokenizer`\n",
    "\n",
    "```python\n",
    "def custom_tokenizer(text):\n",
    "    # Utilisez une expression régulière pour considérer les mots et certains symboles spéciaux\n",
    "    token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b|\\/|<|>|script|alert|http|\\.exe|\\.jpg|=\")\n",
    "    return token_pattern.findall(text)\n",
    "```\n",
    "\n",
    "#### Explication :\n",
    "1. **Expression régulière (`re.compile`) :**\n",
    "   - `r\"(?u)\\b\\w\\w+\\b|\\/|<|>|script|alert|http|\\.exe|\\.jpg|=\"` : Cette expression régulière est utilisée pour définir les motifs de texte (tokens) que la fonction cherchera dans les chaînes de caractères fournies.\n",
    "     - `(?u)` : Ce préfixe rend le motif compatible avec les règles Unicode, permettant une meilleure gestion des caractères non ASCII.\n",
    "     - `\\b\\w\\w+\\b` : Ce motif capture des mots qui contiennent au moins deux caractères alphanumériques (`\\w` correspond à tout caractère alphanumérique). Les `\\b` sont des assertions qui ne correspondent à aucun caractère mais indiquent une limite de mot, ce qui aide à capturer des mots complets.\n",
    "     - `|\\/|<|>|script|alert|http|\\.exe|\\.jpg|=` : Cette partie du motif cherche à capturer des chaînes spécifiques et des symboles qui sont souvent utilisés dans les requêtes malveillantes ou les injections de code (comme les tags `<script>`, des chemins de fichiers, etc.).\n",
    "\n",
    "2. **`token_pattern.findall(text)`** :\n",
    "   - `findall` est une méthode de l'objet `re.Pattern` qui trouve toutes les occurrences non chevauchantes du motif spécifié dans la chaîne de texte donnée et les retourne sous forme de liste.\n",
    "\n",
    "### Configuration du `TfidfVectorizer`\n",
    "\n",
    "```python\n",
    "vectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, lowercase=False, strip_accents=None)\n",
    "```\n",
    "\n",
    "#### Explication :\n",
    "- **`tokenizer=custom_tokenizer`** :\n",
    "  - Cette option indique que `TfidfVectorizer` doit utiliser la fonction `custom_tokenizer` pour diviser le texte en tokens au lieu du tokenizer par défaut.\n",
    "- **`lowercase=False`** :\n",
    "  - Normalement, `TfidfVectorizer` convertit tout le texte en minuscules pour assurer que les tokens comme \"Hello\" et \"hello\" sont traités comme identiques. Ici, cette option est désactivée (`False`), ce qui signifie que la casse sera préservée. Cela peut être utile pour des cas où la casse des lettres change la signification ou est importante pour la détection, comme dans les noms de fichiers ou certaines attaques web.\n",
    "- **`strip_accents=None`** :\n",
    "  - Cette option, lorsqu'elle est désactivée (`None`), ne supprime pas les accents des caractères. Cela peut être important lors de l'analyse de textes dans diverses langues où les accents contribuent à la signification des mots.\n",
    "\n",
    "### Conclusion\n",
    "Ce code est configuré pour traiter spécifiquement des entrées textuelles où des motifs particuliers, tels que des mots, des symboles spéciaux et des suites de caractères techniques, sont essentiels pour l'analyse ou la classification. Il est particulièrement utile pour détecter des caractéristiques spécifiques dans les données, comme des signes d'attaques informatiques dans les requêtes web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorisation TF-IDF\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1er modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://nexus.insee.fr/repository/pypi-proxy/simple\n",
      "Collecting tensorflow\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/tensorflow/2.16.1/tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/absl-py/2.1.0/absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/astunparse/1.6.3/astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/flatbuffers/24.3.25/flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/gast/0.5.4/gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/google-pasta/0.2.0/google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/h5py/3.11.0/h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/libclang/18.1.1/libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/ml-dtypes/0.3.2/ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/opt-einsum/3.3.0/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/termcolor/2.4.0/termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/grpcio/1.63.0/grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/tensorboard/2.16.2/tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/keras/3.3.3/keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/tensorflow-io-gcs-filesystem/0.37.0/tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/mamba/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/rich/13.7.1/rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/namex/0.0.8/namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/optree/0.11.0/optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.0/312.0 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/tensorboard-data-server/0.7.2/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/mamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/markdown-it-py/3.0.0/markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading https://nexus.insee.fr/repository/pypi-proxy/packages/mdurl/0.1.2/mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, markdown-it-py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 09:35:28.589509: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-07 09:35:28.595304: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-07 09:35:28.761935: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-07 09:35:30.434317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/mamba/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 127ms/step - accuracy: 0.8592 - loss: 0.5270\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 109ms/step - accuracy: 0.9579 - loss: 0.1310\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 174ms/step - accuracy: 0.9770 - loss: 0.0696\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 172ms/step - accuracy: 0.9831 - loss: 0.0406\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 171ms/step - accuracy: 0.9956 - loss: 0.0189\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 166ms/step - accuracy: 0.9960 - loss: 0.0151\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 168ms/step - accuracy: 0.9970 - loss: 0.0083\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 167ms/step - accuracy: 0.9966 - loss: 0.0080\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 168ms/step - accuracy: 0.9992 - loss: 0.0053\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 93ms/step - accuracy: 0.9988 - loss: 0.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fa20355f5d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "# Supposons que X_train_tfidf est déjà transformé par TfidfVectorizer et est en format sparse\n",
    "X_train_tfidf_dense = X_train_tfidf.todense()  # Conversion en format dense\n",
    "\n",
    "# Ajout d'une dimension 'timesteps' pour les données\n",
    "X_train_tfidf_dense = np.expand_dims(X_train_tfidf_dense, axis=1)\n",
    "\n",
    "# Maintenant, X_train_tfidf_dense a la forme (batch_size, 1, features)\n",
    "\n",
    "# Supposons que vous avez déjà divisé vos données:\n",
    "# X_train, X_test, y_train, y_test\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Création du modèle avec la bonne dimension d'entrée\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(64, input_shape=(1, X_train_tfidf_dense.shape[2])))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model_lstm.fit(X_train_tfidf_dense, y_train, epochs=10, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle est un exemple d'application d'un réseau de neurones avec des couches LSTM (Long Short-Term Memory) pour traiter des données textuelles transformées en vecteurs TF-IDF (Term Frequency-Inverse Document Frequency) pour une tâche de classification binaire. Voici une explication détaillée du code :\n",
    "\n",
    "### Importation des bibliothèques\n",
    "- `TfidfVectorizer` de `sklearn.feature_extraction.text` est utilisé pour convertir le texte en un vecteur de TF-IDF, une méthode courante pour quantifier l'importance des mots dans des documents par rapport à un corpus.\n",
    "- `numpy` est utilisé pour les manipulations numériques générales dans Python.\n",
    "\n",
    "### Préparation des données\n",
    "- `X_train_tfidf` est supposé être déjà transformé par `TfidfVectorizer` et est en format sparse (matrice creuse). Ce format est généralement utilisé pour économiser de l'espace mémoire lorsque la plupart des valeurs sont des zéros.\n",
    "- `todense()`: Convertit la matrice sparse en une matrice dense. Les matrices denses sont nécessaires pour certaines opérations qui ne peuvent pas être effectuées efficacement avec des matrices sparses.\n",
    "- `np.expand_dims(X_train_tfidf_dense, axis=1)`: Ajoute une dimension supplémentaire aux données, créant une dimension de 'timesteps' requise pour l'entrée dans les couches LSTM. Cela transforme chaque exemple en une séquence d'un timestep avec plusieurs caractéristiques.\n",
    "\n",
    "### Construction du modèle LSTM\n",
    "- `Sequential`: Un modèle séquentiel en Keras, qui permet de créer des modèles couche par couche.\n",
    "- `LSTM(64, input_shape=(1, X_train_tfidf_dense.shape[2]))`: Première couche qui est une couche LSTM avec 64 unités. `input_shape` est défini pour correspondre à la dimension des données (1 timestep, nombre de caractéristiques).\n",
    "- `Dense(1, activation='sigmoid')`: Une couche Dense qui suit la couche LSTM, utilisée pour la classification. La fonction d'activation 'sigmoid' est utilisée pour produire une sortie entre 0 et 1, interprétable comme la probabilité d'appartenance à la classe positive.\n",
    "\n",
    "### Compilation et entraînement du modèle\n",
    "- `model_lstm.compile(...)`: Compile le modèle avec l'optimiseur 'adam', la fonction de perte 'binary_crossentropy' (typique pour la classification binaire), et spécifie 'accuracy' comme métrique pour évaluer le modèle.\n",
    "- `model_lstm.fit(...)`: Entraîne le modèle sur les données d'entraînement, avec des labels `y_train`, pour un nombre spécifié d'époques et de taille de batch.\n",
    "\n",
    "### Application et interprétation\n",
    "Ce modèle est approprié pour la classification de textes où chaque document doit être classé comme appartenant à une classe ou une autre (par exemple, positif/négatif). Les couches LSTM sont particulièrement utiles pour capturer les dépendances à long terme et les séquences dans les données, bien que dans ce cas, chaque document est traité comme une séquence d'un seul élément.\n",
    "\n",
    "En somme, ce modèle illustre comment préparer et utiliser des données textuelles pour la classification binaire en utilisant des réseaux de neurones profonds avec des couches LSTM dans Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **Évaluer le modèle**\n",
    "Vous devriez évaluer votre modèle sur un ensemble de test pour voir comment il performe en termes de précision, de rappel, de F1-score, etc. Cela vous donnera une idée de la qualité de ses prédictions dans un contexte \"réel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que X_test_tfidf a également été transformé en utilisant le même processus que pour X_train_tfidf\n",
    "X_test_tfidf_dense = X_test_tfidf.todense()\n",
    "X_test_tfidf_dense = np.expand_dims(X_test_tfidf_dense, axis=1)\n",
    "\n",
    "# Évaluation du modèle sur les données de test\n",
    "loss, accuracy = model_lstm.evaluate(X_test_tfidf_dense, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Prédire avec le modèle**\n",
    "Utiliser le modèle pour faire des prédictions sur de nouvelles données peut vous aider à voir comment il classifie de nouvelles entrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions\n",
    "predictions = model_lstm.predict(X_test_tfidf_dense)\n",
    "# Convertir les prédictions en labels binaires\n",
    "predicted_labels = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Analyser les résultats**\n",
    "Utilisez les métriques de classification pour analyser les résultats des prédictions. Cela inclut la construction d'une matrice de confusion, ainsi que le calcul de précision, rappel et F1-score pour chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 510 1435]\n",
      " [  10 2045]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.26      0.41      1945\n",
      "           1       0.59      1.00      0.74      2055\n",
      "\n",
      "    accuracy                           0.64      4000\n",
      "   macro avg       0.78      0.63      0.58      4000\n",
      "weighted avg       0.78      0.64      0.58      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test, predicted_labels))\n",
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. **Ajuster le modèle si nécessaire**\n",
    "En fonction des résultats, vous pourriez avoir besoin d'ajuster votre modèle. Cela peut inclure :\n",
    "- Modifier le nombre d'époques.\n",
    "- Changer la structure du réseau (ajouter des couches, changer le nombre de neurones, etc.).\n",
    "- Ajuster les paramètres du modèle (taux d'apprentissage, fonction d'activation, etc.).\n",
    "- Utiliser d'autres techniques de prétraitement ou de feature engineering.\n",
    "\n",
    "### 5. **Sauvegarder le modèle**\n",
    "Si vous êtes satisfait des performances de votre modèle, sauvegardez-le pour une utilisation future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save('my_lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(example_data)\n",
    "# Vectorisation TF-IDF\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "# Supposons que X_train_tfidf est déjà transformé par TfidfVectorizer et est en format sparse\n",
    "X_train_tfidf_dense = X_train_tfidf.todense()  # Conversion en format dense\n",
    "# Ajout d'une dimension 'timesteps' pour les données\n",
    "X_train_tfidf_dense = np.expand_dims(X_train_tfidf_dense, axis=1)\n",
    "# Maintenant, X_train_tfidf_dense a la forme (batch_size, 1, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 154ms/step - accuracy: 0.8787 - loss: 0.5237\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 152ms/step - accuracy: 0.9607 - loss: 0.1255\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 150ms/step - accuracy: 0.9742 - loss: 0.0741\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 163ms/step - accuracy: 0.9831 - loss: 0.0419\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 149ms/step - accuracy: 0.9955 - loss: 0.0212\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
      "[[1905   40]\n",
      " [  71 1984]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1945\n",
      "           1       0.98      0.97      0.97      2055\n",
      "\n",
      "    accuracy                           0.97      4000\n",
      "   macro avg       0.97      0.97      0.97      4000\n",
      "weighted avg       0.97      0.97      0.97      4000\n",
      "\n",
      "Epochs: 5, Test Loss: 0.12103686481714249, Test Accuracy: 0.9722499847412109, Time: 396.03 seconds\n",
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 120ms/step - accuracy: 0.8804 - loss: 0.5235\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 107ms/step - accuracy: 0.9594 - loss: 0.1268\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 103ms/step - accuracy: 0.9771 - loss: 0.0699\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 170ms/step - accuracy: 0.9850 - loss: 0.0375\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 165ms/step - accuracy: 0.9945 - loss: 0.0240\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 153ms/step - accuracy: 0.9957 - loss: 0.0157\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 150ms/step - accuracy: 0.9962 - loss: 0.0111\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 149ms/step - accuracy: 0.9973 - loss: 0.0072\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 151ms/step - accuracy: 0.9974 - loss: 0.0075\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 153ms/step - accuracy: 0.9995 - loss: 0.0033\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step\n",
      "[[ 510 1435]\n",
      " [  10 2045]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.26      0.41      1945\n",
      "           1       0.59      1.00      0.74      2055\n",
      "\n",
      "    accuracy                           0.64      4000\n",
      "   macro avg       0.78      0.63      0.58      4000\n",
      "weighted avg       0.78      0.64      0.58      4000\n",
      "\n",
      "Epochs: 10, Test Loss: 0.40037238597869873, Test Accuracy: 0.6387500166893005, Time: 854.80 seconds\n",
      "Epoch 1/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 149ms/step - accuracy: 0.8978 - loss: 0.5233\n",
      "Epoch 2/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 151ms/step - accuracy: 0.9610 - loss: 0.1268\n",
      "Epoch 3/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 158ms/step - accuracy: 0.9761 - loss: 0.0673\n",
      "Epoch 4/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 166ms/step - accuracy: 0.9832 - loss: 0.0408\n",
      "Epoch 5/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 161ms/step - accuracy: 0.9948 - loss: 0.0223\n",
      "Epoch 6/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 154ms/step - accuracy: 0.9969 - loss: 0.0120\n",
      "Epoch 7/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 176ms/step - accuracy: 0.9951 - loss: 0.0128\n",
      "Epoch 8/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 179ms/step - accuracy: 0.9965 - loss: 0.0065\n",
      "Epoch 9/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 168ms/step - accuracy: 0.9992 - loss: 0.0057\n",
      "Epoch 10/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 170ms/step - accuracy: 0.9991 - loss: 0.0041\n",
      "Epoch 11/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 173ms/step - accuracy: 0.9991 - loss: 0.0033\n",
      "Epoch 12/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 174ms/step - accuracy: 0.9995 - loss: 0.0025\n",
      "Epoch 13/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 166ms/step - accuracy: 0.9994 - loss: 0.0020\n",
      "Epoch 14/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 132ms/step - accuracy: 0.9991 - loss: 0.0028\n",
      "Epoch 15/15\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 175ms/step - accuracy: 0.9994 - loss: 0.0024\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step\n",
      "[[ 498 1447]\n",
      " [   9 2046]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.26      0.41      1945\n",
      "           1       0.59      1.00      0.74      2055\n",
      "\n",
      "    accuracy                           0.64      4000\n",
      "   macro avg       0.78      0.63      0.57      4000\n",
      "weighted avg       0.78      0.64      0.58      4000\n",
      "\n",
      "Epochs: 15, Test Loss: 1.4513400793075562, Test Accuracy: 0.6359999775886536, Time: 1419.09 seconds\n",
      "Epoch 1/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 176ms/step - accuracy: 0.8898 - loss: 0.5226\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 172ms/step - accuracy: 0.9611 - loss: 0.1269\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 172ms/step - accuracy: 0.9750 - loss: 0.0760\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 176ms/step - accuracy: 0.9830 - loss: 0.0416\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 182ms/step - accuracy: 0.9948 - loss: 0.0241\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 167ms/step - accuracy: 0.9955 - loss: 0.0168\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 178ms/step - accuracy: 0.9961 - loss: 0.0104\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 178ms/step - accuracy: 0.9966 - loss: 0.0082\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 164ms/step - accuracy: 0.9978 - loss: 0.0065\n",
      "Epoch 10/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 152ms/step - accuracy: 0.9986 - loss: 0.0047\n",
      "Epoch 11/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 160ms/step - accuracy: 0.9996 - loss: 0.0024\n",
      "Epoch 12/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 141ms/step - accuracy: 0.9994 - loss: 0.0024\n",
      "Epoch 13/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 111ms/step - accuracy: 0.9991 - loss: 0.0025\n",
      "Epoch 14/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 123ms/step - accuracy: 0.9992 - loss: 0.0028\n",
      "Epoch 15/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 140ms/step - accuracy: 0.9995 - loss: 0.0016\n",
      "Epoch 16/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 140ms/step - accuracy: 0.9995 - loss: 0.0012\n",
      "Epoch 17/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 125ms/step - accuracy: 0.9993 - loss: 0.0019\n",
      "Epoch 18/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 95ms/step - accuracy: 0.9994 - loss: 0.0020\n",
      "Epoch 19/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 103ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 20/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 101ms/step - accuracy: 0.9994 - loss: 0.0015\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n",
      "[[ 501 1444]\n",
      " [  10 2045]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.26      0.41      1945\n",
      "           1       0.59      1.00      0.74      2055\n",
      "\n",
      "    accuracy                           0.64      4000\n",
      "   macro avg       0.78      0.63      0.57      4000\n",
      "weighted avg       0.78      0.64      0.58      4000\n",
      "\n",
      "Epochs: 20, Test Loss: 1.3962846994400024, Test Accuracy: 0.6365000009536743, Time: 1678.28 seconds\n"
     ]
    }
   ],
   "source": [
    "# Liste des nombres d'époques à tester\n",
    "epoch_list = [5, 10, 15, 20]\n",
    "\n",
    "# Dictionnaire pour stocker les résultats\n",
    "results = {}\n",
    "\n",
    "\n",
    "for epochs in epoch_list:\n",
    "    # Création du modèle LSTM\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Input(shape=(1, X_train_tfidf_dense.shape[2])))  # Utilisation de Input pour spécifier la forme\n",
    "    model_lstm.add(LSTM(64))\n",
    "    model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compilation du modèle\n",
    "    model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Démarrer le chronomètre\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    model_lstm.fit(X_train_tfidf_dense, y_train, epochs=epochs, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Stopper le chronomètre\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculer le temps total d'entraînement\n",
    "    training_time = end_time - start_time   \n",
    "    \n",
    "    # Évaluation du modèle sur les données de test\n",
    "    loss, accuracy = model_lstm.evaluate(X_test_tfidf_dense, y_test, verbose=0)\n",
    "\n",
    "\n",
    "    # Supposons que X_test_tfidf a également été transformé en utilisant le même processus que pour X_train_tfidf\n",
    "    X_test_tfidf_dense = X_test_tfidf.todense()\n",
    "    X_test_tfidf_dense = np.expand_dims(X_test_tfidf_dense, axis=1)\n",
    "    # Faire des prédictions\n",
    "    predictions = model_lstm.predict(X_test_tfidf_dense)\n",
    "    # Convertir les prédictions en labels binaires\n",
    "    predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted_labels))\n",
    "    print(classification_report(y_test, predicted_labels))\n",
    "    \n",
    "    # Stocker les résultats, y compris le temps d'entraînement\n",
    "    results[epochs] = {'loss': loss, 'accuracy': accuracy, 'time': training_time}\n",
    "    print(f\"Epochs: {epochs}, Test Loss: {loss}, Test Accuracy: {accuracy}, Time: {training_time:.2f} seconds\")\n",
    "\n",
    "    \n",
    "# Vous pouvez maintenant comparer les performances pour chaque configuration d'époque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Liste des époques\n",
    "epochs = list(results.keys())\n",
    "\n",
    "# Extraire les pertes, les précisions et les temps\n",
    "losses = [results[epoch]['loss'] for epoch in epoch_list]\n",
    "accuracies = [results[epoch]['accuracy'] for epoch in epoch_list]\n",
    "times = [results[epoch]['time'] for epoch in epoch_list]\n",
    "\n",
    "# Création du graphique\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Tracer la courbe de perte\n",
    "plt.subplot(1, 2, 1)  # 1 ligne, 2 colonnes, premier subplot\n",
    "plt.plot(epochs, losses, marker='o', color='r')\n",
    "plt.title('Perte par époque')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Perte')\n",
    "plt.grid(True)\n",
    "\n",
    "# Tracer la courbe de précision\n",
    "plt.subplot(1, 2, 2)  # 1 ligne, 2 colonnes, second subplot\n",
    "plt.plot(epochs, accuracies, marker='o', color='b')\n",
    "plt.title('Précision par époque')\n",
    "plt.xlabel('Époques')\n",
    "plt.ylabel('Précision')\n",
    "plt.grid(True)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at your results, it seems that your model's performance changes significantly with the number of epochs during training. Here are some insights and potential actions based on the data provided:\n",
    "\n",
    "### Analysis of Results\n",
    "\n",
    "1. **Epoch 5:**\n",
    "   - **Test Loss:** 0.121\n",
    "   - **Test Accuracy:** 97.22%\n",
    "   - **Time:** 396.03 seconds\n",
    "   - **Observation:** At 5 epochs, the model performs exceptionally well with a high accuracy and a low loss. This is the best performance among all epochs tested.\n",
    "\n",
    "2. **Epoch 10:**\n",
    "   - **Test Loss:** 0.400\n",
    "   - **Test Accuracy:** 63.87%\n",
    "   - **Time:** 854.80 seconds\n",
    "   - **Observation:** Doubling the number of epochs results in a significant drop in performance. This suggests possible overfitting, where the model starts to learn the noise in the training data rather than generalizing from it.\n",
    "\n",
    "3. **Epoch 15 and 20:**\n",
    "   - **Test Loss:** Increases to about 1.451 and 1.396 respectively\n",
    "   - **Test Accuracy:** Stabilizes around 63.6%\n",
    "   - **Time:** Increases significantly with each increment\n",
    "   - **Observation:** Further increases in epochs continue to degrade performance, solidifying the notion that the model might be overfitting. Additionally, the training time increases without any gain in model accuracy or decrease in loss.\n",
    "\n",
    "### Potential Issues and Recommendations\n",
    "\n",
    "- **Overfitting:** As the number of epochs increases, your model seems to fit too closely to the training data, failing to generalize to new, unseen data (evidenced by increasing test loss and decreasing accuracy).\n",
    "- **Training Time:** More epochs lead to longer training times without proportional benefits, making the training process inefficient.\n",
    "\n",
    "### Actions to Consider\n",
    "\n",
    "1. **Early Stopping:** Implement early stopping during training. This technique will halt the training process once the model's performance stops improving on a held-out validation set.\n",
    "2. **Model Regularization:** Techniques such as dropout, L2 regularization (weight decay), or others could help prevent overfitting.\n",
    "3. **Adjust Learning Rate:** Sometimes adjusting the learning rate over time can help manage how the model fits to the data. Consider using learning rate schedules or adaptive learning rate methods like Adam.\n",
    "4. **Cross-validation:** Use cross-validation to ensure that the model’s performance is robust across different subsets of the dataset.\n",
    "5. **Experiment with Different Models:** If overfitting continues to be an issue, it might be worthwhile to experiment with simpler models or different architectures that might generalize better.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Given your results, training the model for fewer epochs (like 5, based on current results) is more advantageous in terms of both accuracy and computational efficiency. Further tuning and the addition of regularization techniques may help improve model stability for higher epochs if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 96ms/step - accuracy: 0.8598 - loss: 0.5520\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 159ms/step - accuracy: 0.9564 - loss: 0.1489\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 171ms/step - accuracy: 0.9735 - loss: 0.0809\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 168ms/step - accuracy: 0.9817 - loss: 0.0494\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 108ms/step - accuracy: 0.9926 - loss: 0.0279\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 102ms/step - accuracy: 0.9957 - loss: 0.0202\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 101ms/step - accuracy: 0.9962 - loss: 0.0141\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.9974 - loss: 0.0072\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 98ms/step - accuracy: 0.9968 - loss: 0.0073\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 95ms/step - accuracy: 0.9987 - loss: 0.0066\n",
      "Score for fold 1: loss of 0.22720757126808167; compile_metrics of 96.28124833106995%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 100ms/step - accuracy: 0.8030 - loss: 0.5571\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 95ms/step - accuracy: 0.9543 - loss: 0.1574\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 101ms/step - accuracy: 0.9722 - loss: 0.0833\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 99ms/step - accuracy: 0.9832 - loss: 0.0479\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 101ms/step - accuracy: 0.9939 - loss: 0.0277\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 100ms/step - accuracy: 0.9950 - loss: 0.0195\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 101ms/step - accuracy: 0.9960 - loss: 0.0135\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 100ms/step - accuracy: 0.9966 - loss: 0.0110\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 100ms/step - accuracy: 0.9967 - loss: 0.0075\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 98ms/step - accuracy: 0.9984 - loss: 0.0064\n",
      "Score for fold 2: loss of 0.3048834800720215; compile_metrics of 95.18749713897705%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 94ms/step - accuracy: 0.8725 - loss: 0.5520\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 95ms/step - accuracy: 0.9567 - loss: 0.1483\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 91ms/step - accuracy: 0.9709 - loss: 0.0824\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 101ms/step - accuracy: 0.9824 - loss: 0.0473\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 98ms/step - accuracy: 0.9948 - loss: 0.0278\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 103ms/step - accuracy: 0.9962 - loss: 0.0174\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 99ms/step - accuracy: 0.9963 - loss: 0.0126\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 105ms/step - accuracy: 0.9960 - loss: 0.0116\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 106ms/step - accuracy: 0.9964 - loss: 0.0090\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 100ms/step - accuracy: 0.9980 - loss: 0.0058\n",
      "Score for fold 3: loss of 0.27278393507003784; compile_metrics of 96.31249904632568%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 105ms/step - accuracy: 0.8856 - loss: 0.5534\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 104ms/step - accuracy: 0.9586 - loss: 0.1460\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 101ms/step - accuracy: 0.9735 - loss: 0.0804\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 153ms/step - accuracy: 0.9831 - loss: 0.0497\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 102ms/step - accuracy: 0.9934 - loss: 0.0304\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 100ms/step - accuracy: 0.9965 - loss: 0.0181\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 102ms/step - accuracy: 0.9967 - loss: 0.0116\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 99ms/step - accuracy: 0.9967 - loss: 0.0109\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 98ms/step - accuracy: 0.9969 - loss: 0.0075\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.9976 - loss: 0.0052\n",
      "Score for fold 4: loss of 0.3254449963569641; compile_metrics of 88.09375166893005%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 100ms/step - accuracy: 0.8696 - loss: 0.5555\n",
      "Epoch 2/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 102ms/step - accuracy: 0.9594 - loss: 0.1476\n",
      "Epoch 3/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 100ms/step - accuracy: 0.9737 - loss: 0.0802\n",
      "Epoch 4/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 105ms/step - accuracy: 0.9818 - loss: 0.0501\n",
      "Epoch 5/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 102ms/step - accuracy: 0.9929 - loss: 0.0280\n",
      "Epoch 6/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 99ms/step - accuracy: 0.9961 - loss: 0.0172\n",
      "Epoch 7/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 101ms/step - accuracy: 0.9960 - loss: 0.0132\n",
      "Epoch 8/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 104ms/step - accuracy: 0.9964 - loss: 0.0095\n",
      "Epoch 9/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.9961 - loss: 0.0094\n",
      "Epoch 10/10\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 102ms/step - accuracy: 0.9975 - loss: 0.0086\n",
      "Score for fold 5: loss of 0.23830446600914001; compile_metrics of 96.78124785423279%\n",
      "Average Loss: 0.273724889755249\n",
      "Average Accuracy: 94.5312488079071%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "import numpy as np\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for train, test in kfold.split(X_train_tfidf_dense, y_train):\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(1, X_train_tfidf_dense.shape[2])))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(X_train_tfidf_dense[train], y_train.iloc[train], \n",
    "                        epochs=10, \n",
    "                        batch_size=32, \n",
    "                        verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_train_tfidf_dense[test], y_train.iloc[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    losses.append(scores[0])\n",
    "    accuracies.append(scores[1])\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# Print overall results\n",
    "average_loss = np.mean(losses)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Loss: {average_loss}')\n",
    "print(f'Average Accuracy: {average_accuracy * 100}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
